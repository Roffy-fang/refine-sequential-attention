# refine-sequential-attention

### Before all
This work is forked from fabulous [neuraltalk2](https://github.com/karpathy/neuraltalk2) from [karparthy](https://github.com/karpathy). And the model implemented here is from "Refining Attention: a Sequential Attention Model for Image Captioning" accepted by IEEE International Conference on Multimedia and Expoâ€™18
### Overview 
 
![overview](https://github.com/Roffy-fang/refine-sequential-attention/blob/master/vis/fig1.jpg)
 
### License

BSD License.

### Acknowledgements

Parts of this code were written in collaboration with my labmate [Justin Johnson](http://cs.stanford.edu/people/jcjohns/). 

I'm very grateful for [NVIDIA](https://developer.nvidia.com/deep-learning)'s support in providing GPUs that made this work possible.

I'm also very grateful to the maintainers of Torch for maintaining a wonderful deep learning library.
